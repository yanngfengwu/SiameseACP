{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0881980a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "import time\n",
    "import pickle\n",
    "from termcolor import colored\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import random\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "# torch.cuda.set_device(2)\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '2'\n",
    "pep2label = list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5186d15",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:17\u001b[0;36m\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def genData(file, max_len):\n",
    "#     aa_dict = {'A': 1, 'C': 2, 'T': 3, 'G': 4}\n",
    "    aa_dict = {'A': 1, 'R': 2, 'N': 3, 'D': 4, 'C': 5, 'Q': 6, 'E': 7, 'G': 8, 'H': 9, 'I': 10,\n",
    "               'L': 11, 'K': 12, 'M': 13, 'F': 14, 'P': 15, 'O': 16, 'S': 17, 'U': 18, 'T': 19,\n",
    "               'W': 20, 'Y': 21, 'V': 22, 'X': 23}\n",
    "    with open(file, 'r') as inf:\n",
    "        lines = inf.read().splitlines()\n",
    "\n",
    "    long_pep_counter = 0\n",
    "    pep_codes = []\n",
    "    labels = []\n",
    "    pep_seq = []\n",
    "    max_seq_len = 70\n",
    "    for pep in lines:\n",
    "        if line[0] == '>':\n",
    "                key = line[1:].split('\\n')[0]\n",
    "            else:\n",
    "                enhancers.append({key: line.split('\\n')[0]})\n",
    "        pep, label = pep.split(\",\")\n",
    "        labels.append(int(label))\n",
    "        input_seq = ' '.join(pep)\n",
    "        input_seq = re.sub(r\"[UZOB]\", \"X\", input_seq)\n",
    "        pep_seq.append(input_seq)\n",
    "        if not len(pep) > max_len:\n",
    "            current_pep = []\n",
    "            for aa in pep:\n",
    "                current_pep.append(aa_dict[aa])\n",
    "            pep_codes.append(torch.tensor(current_pep))\n",
    "        else:\n",
    "            long_pep_counter += 1\n",
    "    print(\"length > 200:\", long_pep_counter)\n",
    "    data = rnn_utils.pad_sequence(pep_codes, batch_first=True)\n",
    "\n",
    "    return data, torch.tensor(labels), pep_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10c71a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_first_layer_data(path):# ../benchmark dataset & ../independent dataset\n",
    "    '''\n",
    "\n",
    "    :param path:\n",
    "    :return:\n",
    "    1 represents enhancer\n",
    "    0 represents non-enhancer\n",
    "    '''\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    datas = []\n",
    "    path_enhancer = os.path.join(path, 'first layer/enhancers.txt')\n",
    "    path_non_enhancer = os.path.join(path, 'first layer/non-enhancers.txt')\n",
    "    aa_dict = {'A': 1, 'C': 2, 'T': 3, 'G': 4}\n",
    "    with open(path_enhancer, encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            # print(line)\n",
    "            if line[0] == '>':\n",
    "                continue\n",
    "            else:\n",
    "                sequences.append(line.split('\\n')[0][:50])\n",
    "                labels.append(1)\n",
    "                current_DNA = []\n",
    "                for aa in line.split('\\n')[0][:50]:\n",
    "                    current_DNA.append(aa_dict[aa])\n",
    "                datas.append(current_DNA)\n",
    "    with open(path_non_enhancer, encoding='utf-8') as f:\n",
    "        for line in f.readlines():\n",
    "            if line[0] == '>':\n",
    "                continue\n",
    "            else:\n",
    "                sequences.append(line.split('\\n')[0][:50])\n",
    "                labels.append(0)\n",
    "                current_DNA = []\n",
    "                for aa in line.split('\\n')[0][:50]:\n",
    "                    current_DNA.append(aa_dict[aa])\n",
    "                datas.append(current_DNA)\n",
    "\n",
    "    return torch.tensor(datas), torch.tensor(labels), sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aab35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9db8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prelabel(data_iter, net):\n",
    "    prelabel, relabel = [], []\n",
    "    for x, y, z in data_iter:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "#         for i in range(len(z)):\n",
    "#             if i == 0:\n",
    "#                 vec = torch.tensor(seq2vec[z[0]]).to(device)\n",
    "#             else:\n",
    "#                 vec = torch.cat((vec, torch.tensor(seq2vec[z[i]]).to(device)), dim=0)\n",
    "        outputs = net.trainModel(x)\n",
    "        prelabel.append(outputs.argmax(dim=1).cpu().numpy())\n",
    "        relabel.append(y.cpu().numpy())\n",
    "        # print()\n",
    "    return prelabel, relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ac9fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/sdb/home/yxt/newMyiEnhancer', '/home/weilab/anaconda3/envs/jjr/lib/python310.zip', '/home/weilab/anaconda3/envs/jjr/lib/python3.10', '/home/weilab/anaconda3/envs/jjr/lib/python3.10/lib-dynload', '', '/home/weilab/anaconda3/envs/jjr/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "\n",
    "\n",
    "def caculate_metric(pred_y, labels, pred_prob):\n",
    "\n",
    "    test_num = len(labels)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "\n",
    "    for index in range(test_num):\n",
    "        if int(labels[index]) == 1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp + 1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn + 1\n",
    "            else:\n",
    "                fp = fp + 1\n",
    "\n",
    "\n",
    "    ACC = float(tp + tn) / test_num\n",
    "\n",
    "    # precision\n",
    "    if tp + fp == 0:\n",
    "        Precision = 0\n",
    "    else:\n",
    "        Precision = float(tp) / (tp + fp)\n",
    "\n",
    "    # SE\n",
    "    if tp + fn == 0:\n",
    "        Recall = Sensitivity = 0\n",
    "    else:\n",
    "        Recall = Sensitivity = float(tp) / (tp + fn)\n",
    "\n",
    "    # SP\n",
    "    if tn + fp == 0:\n",
    "        Specificity = 0\n",
    "    else:\n",
    "        Specificity = float(tn) / (tn + fp)\n",
    "\n",
    "    # MCC\n",
    "    if (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn) == 0:\n",
    "        MCC = 0\n",
    "    else:\n",
    "        MCC = float(tp * tn - fp * fn) / (np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "\n",
    "    # F1-score\n",
    "    if Recall + Precision == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2 * Recall * Precision / (Recall + Precision)\n",
    "\n",
    "    # ROC and AUC\n",
    "    labels = list(map(int, labels))\n",
    "    pred_prob = list(map(float, pred_prob))\n",
    "    fpr, tpr, thresholds = roc_curve(labels, pred_prob, pos_label=1)  # 默认1就是阳性\n",
    "    AUC = auc(fpr, tpr)\n",
    "\n",
    "    # PRC and AP\n",
    "    precision, recall, thresholds = precision_recall_curve(labels, pred_prob, pos_label=1)\n",
    "    AP = average_precision_score(labels, pred_prob, average='macro', pos_label=1, sample_weight=None)\n",
    "\n",
    "    metric = torch.tensor([ACC, Precision, Sensitivity, Specificity, F1, AUC, MCC])\n",
    "\n",
    "    # ROC(fpr, tpr, AUC)\n",
    "    # PRC(recall, precision, AP)\n",
    "    roc_data = [fpr, tpr, AUC]\n",
    "    prc_data = [recall, precision, AP]\n",
    "    return metric, roc_data, prc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b49d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2968, 50]) torch.Size([2968])\n",
      "torch.Size([400, 50]) torch.Size([400])\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, train_seq = get_first_layer_data(\"./dataset/benchmark dataset\")\n",
    "test_data, test_label, test_seq = get_first_layer_data(\"./dataset/independent dataset\")\n",
    "\n",
    "print(train_data.shape, train_label.shape)\n",
    "print(test_data.shape,test_label.shape)\n",
    "\n",
    "class MyDataSet(Data.Dataset):\n",
    "    def __init__(self, data, label, seq):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.seq = seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.label[idx], self.seq[idx]\n",
    "\n",
    "train_dataset = MyDataSet(train_data, train_label, train_seq)\n",
    "test_dataset = MyDataSet(test_data, test_label, test_seq)\n",
    "\n",
    "batch_size = 128\n",
    "train_iter = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "# seq2vec = json.load(open('../seq2vec_CPP.emb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69c43f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=24):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = 25\n",
    "        self.emb_dim = 512\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=1)\n",
    "\n",
    "        self.gru = nn.GRU(self.emb_dim, self.hidden_dim, num_layers=2,\n",
    "                          bidirectional=True, dropout=0.4)\n",
    "        self.bilstm = nn.LSTM(input_size=self.emb_dim,hidden_size=self.hidden_dim,num_layers=4,bidirectional=True,dropout=0.5)\n",
    "        self.linear = nn.Sequential(nn.Linear(1024, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(256, 32),\n",
    "                                    nn.BatchNorm1d(32),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(32, 1),\n",
    "                                    )\n",
    "\n",
    "        self.block1 = nn.Sequential(nn.Linear(10000, 2048),\n",
    "                                    nn.BatchNorm1d(2048),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(2048, 1024),\n",
    "                                    )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "#             nn.BatchNorm1d(2048),\n",
    "#             nn.LeakyReLU(),\n",
    "#             nn.Linear(2048, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 640),\n",
    "            nn.BatchNorm1d(640),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(640, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.embedding(x)\n",
    "        output = self.transformer_encoder(x).permute(1, 0, 2)\n",
    "\n",
    "        #GRU\n",
    "        output, hn = self.gru(output)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        hn = hn.permute(1, 0, 2)\n",
    "        output = output.reshape(output.shape[0], -1)\n",
    "        return self.block1(output)\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "\n",
    "        return self.block2(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b1a7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class newModel(nn.Module):\n",
    "    def __init__(self, vocab_size=4):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.filter_sizes = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "        self.filter_sizes = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "        self.embedding_dim = 100  # the MGF process dim\n",
    "        dim_cnn_out = 128\n",
    "        filter_num = 64\n",
    "\n",
    "        # self.filter_sizes = [int(fsz) for fsz in self.filter_sizes.split(',')]\n",
    "        self.embedding = nn.Embedding(vocab_size, self.embedding_dim, padding_idx=0)\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [nn.Conv2d(1, filter_num, (fsz, self.embedding_dim)) for fsz in self.filter_sizes])\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # self.linear = nn.Linear(len(self.filter_sizes) * filter_num, dim_cnn_out)\n",
    "        # self.classification = nn.Linear(dim_cnn_out, 2)  # label_num: 28\n",
    "        # 已经2分类了，不用改\n",
    "        # self.classification = nn.Sequential(\n",
    "        #     nn.Linear(len(self.filter_sizes) * filter_num, 256),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(256, 64),\n",
    "        #     nn.Dropout(0.5),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.Linear(64, 2)\n",
    "        # )\n",
    "        self.block1 = nn.Sequential(nn.Linear(len(self.filter_sizes) * filter_num, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.LeakyReLU(),\n",
    "                                    nn.Linear(256, 64),\n",
    "                                    )\n",
    "        self.classification = nn.Sequential(\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.cuda()\n",
    "        # print(x.shape)\n",
    "        # # 输入x的维度为(batch_size, max_len), max_len可以通过torchtext设置或自动获取为训练样本的最大=长度\n",
    "        # print('raw x', x.size())\n",
    "        # input_ids = x\n",
    "        x = self.embedding(x)  # 经过embedding,x的维度为(batch_size, max_len, embedding_dim)\n",
    "        # print('embedding x', x.size())\n",
    "\n",
    "        # 经过view函数x的维度变为(batch_size, input_chanel=1, w=max_len, h=embedding_dim)\n",
    "        x = x.view(x.size(0), 1, x.size(1), self.embedding_dim)\n",
    "        # print('view x', x.size())\n",
    "\n",
    "        # 经过卷积运算,x中每个运算结果维度为(batch_size, out_chanel, w, h=1)\n",
    "        x = [F.relu(conv(x)) for conv in self.convs]\n",
    "        # print(x)\n",
    "        # print('conv x', len(x), [x_item.size() for x_item in x])\n",
    "\n",
    "        # 经过最大池化层,维度变为(batch_size, out_chanel, w=1, h=1)\n",
    "        x = [F.max_pool2d(input=x_item, kernel_size=(x_item.size(2), x_item.size(3))) for x_item in x]\n",
    "        # print('max_pool2d x', len(x), [x_item.size() for x_item in x])\n",
    "\n",
    "        # 将不同卷积核运算结果维度（batch，out_chanel,w,h=1）展平为（batch, outchanel*w*h）\n",
    "        x = [x_item.view(x_item.size(0), -1) for x_item in x]\n",
    "        # print('flatten x', len(x), [x_item.size() for x_item in x])\n",
    "\n",
    "        # 将不同卷积核提取的特征组合起来,维度变为(batch, sum:outchanel*w*h)\n",
    "        x = torch.cat(x, 1)\n",
    "        # print('concat x', x.size()) torch.Size([320, 1024])\n",
    "\n",
    "        # dropout层\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # 全连接层\n",
    "        # representation = self.linear(x)\n",
    "        output = self.block1(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def trainModel(self, x):\n",
    "        with torch.no_grad():\n",
    "            output = self.forward(x)\n",
    "\n",
    "        return self.block1(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fe5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextCNN, self).__init__()\n",
    "        \n",
    "        )\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbb0f4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        # euclidean_distance: [128]\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
    "        loss_contrastive = torch.mean((1 - label) * torch.pow(euclidean_distance, 2) +  # calmp夹断用法\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63f9099b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m label3 \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m num_model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     net \u001b[38;5;241m=\u001b[39m \u001b[43mnewModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.00001\u001b[39m\n\u001b[1;32m     55\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m)\n",
      "File \u001b[0;32m/home/weilab/anaconda3/envs/jjr/lib/python3.10/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/weilab/anaconda3/envs/jjr/lib/python3.10/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/home/weilab/anaconda3/envs/jjr/lib/python3.10/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/home/weilab/anaconda3/envs/jjr/lib/python3.10/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: all CUDA-capable devices are busy or unavailable\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "\n",
    "def collate(batch):\n",
    "    seq1_ls = []\n",
    "    seq2_ls = []\n",
    "    label1_ls = []\n",
    "    label2_ls = []\n",
    "    label_ls = []\n",
    "    pep1_ls = []\n",
    "    pep2_ls = []\n",
    "    batch_size = len(batch)\n",
    "    for i in range(int(batch_size / 2)):\n",
    "        seq1, label1, pep_seq1 = batch[i][0], batch[i][1], batch[i][2]\n",
    "        seq2, label2, pep_seq2 = batch[i + int(batch_size / 2)][0], batch[i + int(batch_size / 2)][1], batch[i + int(batch_size / 2)][2]\n",
    "        label1_ls.append(label1.unsqueeze(0))\n",
    "        label2_ls.append(label2.unsqueeze(0))\n",
    "        pep1_ls.append(pep_seq1)\n",
    "        pep2_ls.append(pep_seq2)\n",
    "        label = (label1 ^ label2)\n",
    "        seq1_ls.append(seq1.unsqueeze(0))\n",
    "        seq2_ls.append(seq2.unsqueeze(0))\n",
    "        label_ls.append(label.unsqueeze(0))\n",
    "    seq1 = torch.cat(seq1_ls).to(device)\n",
    "    seq2 = torch.cat(seq2_ls).to(device)\n",
    "    label = torch.cat(label_ls).to(device)\n",
    "    label1 = torch.cat(label1_ls).to(device)\n",
    "    label2 = torch.cat(label2_ls).to(device)\n",
    "    return seq1, seq2, label, label1, label2, pep1_ls, pep2_ls\n",
    "\n",
    "\n",
    "train_iter_cont = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                              shuffle=True, collate_fn=collate)\n",
    "\n",
    "device = torch.device(\"cuda\", 1)\n",
    "\n",
    "\n",
    "def evaluate_accuracy(data_iter, net):\n",
    "    acc_sum, n = 0.0, 0\n",
    "    for x, y, z in data_iter:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "#         for i in range(len(z)):\n",
    "#             if i == 0:\n",
    "#                 vec = torch.tensor(seq2vec[z[0]]).to(device)\n",
    "#             else:\n",
    "#                 vec = torch.cat((vec, torch.tensor(seq2vec[z[i]]).to(device)), dim=0)\n",
    "        outputs = net.trainModel(x)\n",
    "\n",
    "        acc_sum += (outputs.argmax(dim=1) == y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "\n",
    "output5 = []\n",
    "label3 = []\n",
    "for num_model in range(10):\n",
    "    net = newModel().to(device)\n",
    "    lr = 0.00001\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    criterion = ContrastiveLoss()\n",
    "\n",
    "    criterion_model = nn.CrossEntropyLoss(reduction='sum')\n",
    "    best_acc = 0\n",
    "    EPOCH = 2000\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        loss_ls = []\n",
    "        loss1_ls = []\n",
    "        loss2_3_ls = []\n",
    "\n",
    "\n",
    "        t0 = time.time()\n",
    "        net.train()\n",
    "\n",
    "        for seq1, seq2, label, label1, label2, pep1, pep2 in train_iter_cont:\n",
    "\n",
    "            output1 = net(seq1)\n",
    "            output2 = net(seq2)\n",
    "            output3 = net.trainModel(seq1)\n",
    "            output4 = net.trainModel(seq2)\n",
    "            loss1 = criterion(output1, output2, label)\n",
    "            loss2 = criterion_model(output3, label1)\n",
    "            loss3 = criterion_model(output4, label2)\n",
    "#             loss = loss1 + loss2 + loss3\n",
    "            loss = loss2 + loss3\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_ls.append(loss.item())\n",
    "            loss1_ls.append(loss1.item())\n",
    "            loss2_3_ls.append((loss2 + loss3).item())\n",
    "            output5.extend([output1, output2])\n",
    "            label3.extend([label1, label2])\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "#             print(2)\n",
    "            train_acc = evaluate_accuracy(train_iter, net)\n",
    "#             print(1)\n",
    "            test_acc = evaluate_accuracy(test_iter, net)\n",
    "            A, B = get_prelabel(test_iter, net)\n",
    "            A = [np.concatenate(A)]\n",
    "            B = [np.concatenate(B)]\n",
    "            A = np.array(A)\n",
    "            B = np.array(B)\n",
    "            A = A.reshape(-1, 1)\n",
    "            B = B.reshape(-1, 1)\n",
    "\n",
    "            df1 = pd.DataFrame(A, columns=['prelabel'])\n",
    "            df2 = pd.DataFrame(B, columns=['realabel'])\n",
    "            df4 = pd.concat([df1, df2], axis=1)\n",
    "\n",
    "\n",
    "            acc_sum, n = 0.0, 0\n",
    "            outputs = []\n",
    "            for x, y, z in test_iter:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "#                 for i in range(len(z)):\n",
    "#                     if i == 0:\n",
    "#                         vec = torch.tensor(seq2vec[z[0]]).to(device)\n",
    "#                     else:\n",
    "#                         vec = torch.cat((vec, torch.tensor(seq2vec[z[i]]).to(device)), dim=0)\n",
    "                output = torch.softmax(net.trainModel(x), dim=1)\n",
    "                outputs.append(output)\n",
    "            outputs = torch.cat(outputs, dim=0)\n",
    "            pre_pro = outputs[:, 1]\n",
    "            pre_pro = np.array(pre_pro.cpu().detach().numpy())\n",
    "            pre_pro = pre_pro.reshape(-1)\n",
    "            df3 = pd.DataFrame(pre_pro, columns=['pre_pro'])\n",
    "            df5 = pd.concat([df4, df3], axis=1)\n",
    "            real1 = df5['realabel']\n",
    "            pre1 = df5['prelabel']\n",
    "            pred_pro1 = df5['pre_pro']\n",
    "            metric1, roc_data1, prc_data1 = caculate_metric(pre1, real1, pred_pro1)\n",
    "\n",
    "\n",
    "        results = f\"epoch: {epoch + 1}, loss: {np.mean(loss_ls):.5f}, loss1: {np.mean(loss1_ls):.5f}, loss2_3: {np.mean(loss2_3_ls):.5f}\\n\"\n",
    "        results += f'\\ttrain_acc: {train_acc:.4f}, test_acc: {colored(test_acc, \"red\")}, time: {time.time() - t0:.2f}'\n",
    "        print(results)\n",
    "\n",
    "\n",
    "        if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "\n",
    "\n",
    "            torch.save({\"best_acc\": best_acc,\"metric\":metric1, \"model\": net.state_dict()}, f'./{num_model}.pl')\n",
    "            print(f\"best_acc: {best_acc},metric:{metric1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89508b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
